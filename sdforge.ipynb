{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GnmYPpV3o719"
      },
      "source": [
        "# **Android's Forge Colab**\n",
        "# Forked from (cagliostro-forge-colab)\n",
        "Rise from the ashes, reborn and empowered by [lllyasviel/stable-diffusion-webui-forge](https://github.com/lllyasviel/stable-diffusion-webui-forge)\n",
        "\n",
        "Changelog:\n",
        "- Added Adetailer\n",
        "- Added CivitAI Browser extension (You can now download loras directly in the WebUI)\n",
        "- Added 4xAnimeSharp as ESRGAN.\n",
        "- Added Anzhc Yolov5 adetailer models.\n",
        "- Added Field to input CivitAI token to download civitai models.\n",
        "- Added SD Forge Couple extension.\n",
        "- Added Flux1D and Schnell Lora for Flux1D\n",
        "- Added Option for including a \"Custom Lora Directory\" where you can load a directory of loras from google drive.\n",
        "- Added New Field for inputting a custom upscaler, along with 4xUltraSharp as a default model.\n",
        "- Added Yolo adetailer models for Hand and Feet.\n",
        "- Added Hassaku XL (Illustrious) as a new default model.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "YYzHDlgEkkrY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "448e2262-bfa7-41e0-eb1d-31c977aa04f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[0;32m================================================================================\u001b[0m\n",
            "\u001b[0m\u001b[0;32mMounting google drive...\n",
            "Mounted at /content/drive\n",
            "\u001b[0m\u001b[0;32mSet default output path to: /content/drive/MyDrive/android-colab-forge\u001b[0m\n",
            "\u001b[0m\u001b[0;32m================================================================================\u001b[0m\n",
            "\u001b[0m\u001b[38;2;255;204;0m [-] Current GPU: Tesla T4\u001b[0m\n",
            "\u001b[0m\u001b[38;2;255;204;0m [-] Python 3.12.12 (main, Oct 10 2025, 08:52:57) [GCC 11.4.0]\u001b[0m\n",
            "\u001b[0m\u001b[38;2;255;204;0m [-] Torch 2.9.0+cu126\u001b[0m\n",
            "\u001b[0m\u001b[0;32m================================================================================\u001b[0m\n",
            "\u001b[0m\u001b[0;32mInstalling ubuntu dependencies\u001b[0m\n",
            "\u001b[0m\u001b[0;32m================================================================================\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[0m\u001b[0;32mUnpacking Web UI forge: 100%|██████████| 2/2 [00:12<00:00,  6.01s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[0;32mPreparing environment...\u001b[0m\n",
            "\u001b[0m\u001b[0;32m================================================================================\u001b[0m\n",
            "\u001b[0m\u001b[0;32m'lllyasviel/stable-diffusion-webui-forge' updated to the latest version\u001b[0m\n",
            "\u001b[0m\u001b[0;32mUsing 'lllyasviel/stable-diffusion-webui-forge' repository...\u001b[0m\n",
            "\u001b[0m\u001b[0;32mBranch: main, Commit hash: dfdcbab685e57677014f05a3309b48cc87383167\u001b[0m\n",
            "\u001b[0m\u001b[0;32m================================================================================\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[0m\u001b[0;32mUpdating extensions: 100%|██████████| 5/5 [00:02<00:00,  1.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[0;32m [-] 'Haoming02/sd-webui-vectorscope-cc' updated to the latest version\u001b[0m\n",
            "\u001b[0m\u001b[0;32m [-] 'gutris1/sd-hub' updated to the latest version\u001b[0m\n",
            "\u001b[0m\u001b[0;32m [-] 'hako-mikan/sd-webui-supermerger' updated to the latest version\u001b[0m\n",
            "\u001b[0m\u001b[0;32m [-] 'zanllp/sd-webui-infinite-image-browsing' updated to the latest version\u001b[0m\n",
            "\u001b[0m\u001b[0;32m [-] 'DominikDoom/a1111-sd-webui-tagcomplete' updated to the latest version\u001b[0m\n",
            "\u001b[0m\u001b[0;32m================================================================================\u001b[0m\n",
            "\u001b[0m\u001b[0;32mInstalling ADetailer Reforge...\u001b[0m\n",
            "Cloning into '/content/stable-diffusion-webui-forge/extensions/aadetailer-reforge'...\n",
            "remote: Enumerating objects: 3147, done.\u001b[K\n",
            "remote: Counting objects: 100% (998/998), done.\u001b[K\n",
            "remote: Compressing objects: 100% (128/128), done.\u001b[K\n",
            "remote: Total 3147 (delta 945), reused 870 (delta 870), pack-reused 2149 (from 3)\u001b[K\n",
            "Receiving objects: 100% (3147/3147), 578.88 KiB | 15.23 MiB/s, done.\n",
            "Resolving deltas: 100% (1849/1849), done.\n",
            "\u001b[0m\u001b[0;32m================================================================================\u001b[0m\n",
            "\u001b[0m\u001b[0;32mInstalling Adetailer/Yolo models...\u001b[0m\n",
            "\u001b[0m\u001b[0;32mStarting download of 'Anzhc Breasts Seg v1 1024m.pt' with aria2c...\u001b[0m\n",
            "\u001b[0m\u001b[0;32mDownload of 'Anzhc Breasts Seg v1 1024m.pt' completed. Took 0 sec.\u001b[0m\n",
            "\u001b[0m\u001b[0;32mStarting download of 'Anzhc Eyes -seg-hd.pt' with aria2c...\u001b[0m\n",
            "\u001b[0m\u001b[0;32mDownload of 'Anzhc Eyes -seg-hd.pt' completed. Took 0 sec.\u001b[0m\n",
            "\u001b[0m\u001b[0;32mStarting download of 'Anzhc Face -seg.pt' with aria2c...\u001b[0m\n",
            "\u001b[0m\u001b[0;32mDownload of 'Anzhc Face -seg.pt' completed. Took 0 sec.\u001b[0m\n",
            "\u001b[0m\u001b[0;32mStarting download of 'Anzhc Face seg 1024 v2 y8n.pt' with aria2c...\u001b[0m\n",
            "\u001b[0m\u001b[0;32mDownload of 'Anzhc Face seg 1024 v2 y8n.pt' completed. Took 0 sec.\u001b[0m\n",
            "\u001b[0m\u001b[0;32mStarting download of 'Anzhc HeadHair seg y8m.pt' with aria2c...\u001b[0m\n",
            "\u001b[0m\u001b[0;32mDownload of 'Anzhc HeadHair seg y8m.pt' completed. Took 0 sec.\u001b[0m\n",
            "\u001b[0m\u001b[0;32mStarting download of 'Anzhc Manga Panels -seg.pt' with aria2c...\u001b[0m\n",
            "\u001b[0m\u001b[0;32mDownload of 'Anzhc Manga Panels -seg.pt' completed. Took 0 sec.\u001b[0m\n",
            "\u001b[0m\u001b[0;32mStarting download of 'Anzhcs ManFace v02 1024 y8n.pt' with aria2c...\u001b[0m\n",
            "\u001b[0m\u001b[0;32mDownload of 'Anzhcs ManFace v02 1024 y8n.pt' completed. Took 0 sec.\u001b[0m\n",
            "\u001b[0m\u001b[0;32mStarting download of 'Anzhcs WomanFace v05 1024 y8n.pt' with aria2c...\u001b[0m\n",
            "\u001b[0m\u001b[0;32mDownload of 'Anzhcs WomanFace v05 1024 y8n.pt' completed. Took 0 sec.\u001b[0m\n",
            "\u001b[0m\u001b[0;32mStarting download of 'hand_yolov9c.pt' with aria2c...\u001b[0m\n",
            "\u001b[0m\u001b[0;32mDownload of 'hand_yolov9c.pt' completed. Took 0 sec.\u001b[0m\n",
            "\u001b[0m\u001b[0;32mStarting download of 'foot_yolov8x_v2.pt' with aria2c...\u001b[0m\n",
            "\u001b[0m\u001b[0;32mDownload of 'foot_yolov8x_v2.pt' completed. Took 1 sec.\u001b[0m\n",
            "\u001b[0m\u001b[0;32m================================================================================\u001b[0m\n",
            "\u001b[0m\u001b[0;32mDownloading Custom ADetailer Models...\u001b[0m\n",
            "\u001b[0m\u001b[0;32mStarting download of 'handDetailer_v2V9c.zip' with aria2c...\u001b[0m\n",
            "\u001b[0m\u001b[0;32mDownload of 'handDetailer_v2V9c.zip' completed. Took 0 sec.\u001b[0m\n",
            "\u001b[0m\u001b[0;32mExtracting handDetailer_v2V9c.zip...\u001b[0m\n",
            "\u001b[0m\u001b[0;32mExtracted and removed archive: handDetailer_v2V9c.zip\u001b[0m\n",
            "\u001b[0m\u001b[38;2;255;204;0mhandDetailer_v2V9c.zip Adetailer model has been downloaded\u001b[0m\n",
            "\u001b[0m\u001b[0;32m================================================================================\u001b[0m\n",
            "\u001b[0m\u001b[0;32mInstalling ESRGAN models...\u001b[0m\n",
            "\u001b[0m\u001b[0;32mStarting download of '4x-AnimeSharp.safetensors' with aria2c...\u001b[0m\n",
            "\u001b[0m\u001b[0;32mDownload of '4x-AnimeSharp.safetensors' completed. Took 0 sec.\u001b[0m\n",
            "\u001b[0m\u001b[0;32mStarting download of '4x-UltraSharp.pth' with aria2c...\u001b[0m\n",
            "\u001b[0m\u001b[0;32mDownload of '4x-UltraSharp.pth' completed. Took 0 sec.\u001b[0m\n",
            "\u001b[0m\u001b[0;32mModel 4x-AnimeSharp.safetensors already exists, skipping...\u001b[0m\n",
            "\u001b[0m\u001b[0;32mModel 4x-UltraSharp.pth already exists, skipping...\u001b[0m\n",
            "\u001b[0m\u001b[0;32m================================================================================\u001b[0m\n",
            "\u001b[0m\u001b[0;32mInstalling Civitai Downloader...\u001b[0m\n",
            "Cloning into '/content/stable-diffusion-webui-forge/extensions/sd-webui-civitai-downloader'...\n",
            "remote: Enumerating objects: 96, done.\u001b[K\n",
            "remote: Counting objects: 100% (96/96), done.\u001b[K\n",
            "remote: Compressing objects: 100% (74/74), done.\u001b[K\n",
            "Receiving objects: 100% (96/96), 40.66 KiB | 5.81 MiB/s, done.\n",
            "remote: Total 96 (delta 51), reused 62 (delta 22), pack-reused 0 (from 0)\u001b[K\n",
            "Resolving deltas: 100% (51/51), done.\n",
            "\u001b[0m\u001b[0;32m================================================================================\u001b[0m\n",
            "\u001b[0m\u001b[0;32mInstalling SD Forge Couple...\u001b[0m\n",
            "Cloning into '/content/stable-diffusion-webui-forge/extensions/sd-forge-couple'...\n",
            "remote: Enumerating objects: 1072, done.\u001b[K\n",
            "remote: Counting objects: 100% (428/428), done.\u001b[K\n",
            "remote: Compressing objects: 100% (172/172), done.\u001b[K\n",
            "remote: Total 1072 (delta 285), reused 281 (delta 249), pack-reused 644 (from 2)\u001b[K\n",
            "Receiving objects: 100% (1072/1072), 11.88 MiB | 34.27 MiB/s, done.\n",
            "Resolving deltas: 100% (684/684), done.\n",
            "\u001b[0m\u001b[0;32m================================================================================\u001b[0m\n",
            "\u001b[0m\u001b[0;32m================================================================================\u001b[0m\n",
            "\u001b[0m\u001b[0;32mInstalling custom loras from ''\u001b[0m\n",
            "\u001b[0m\u001b[0;31mNo loras found in the custom lora directory, skipping...\u001b[0m\n",
            "\u001b[0m\u001b[0;32mInstalling custom loras finished.\u001b[0m\n",
            "\u001b[0m\u001b[38;2;255;204;0mFinished installation. Took 1 mins 40 sec.\u001b[0m\n",
            "\u001b[0m\u001b[0;32m================================================================================\u001b[0m\n",
            "\u001b[0m\u001b[38;2;255;204;0m [-] Downloading Custom model...\u001b[0m\n",
            "\u001b[0m\u001b[0;32m================================================================================\u001b[0m\n",
            "\u001b[0m\u001b[0;32mStarting download of 'waiIllustriousSDXL_v160.safetensors' with aria2c...\u001b[0m\n",
            "\u001b[0m\u001b[0;32mDownload of 'waiIllustriousSDXL_v160.safetensors' completed. Took 42 sec.\u001b[0m\n",
            "\u001b[0m\u001b[0;32m================================================================================\u001b[0m\n",
            "\u001b[0m\u001b[0;32mStarting download of 'redLilyIllu_v10.safetensors' with aria2c...\u001b[0m\n",
            "\u001b[0m\u001b[0;32mDownload of 'redLilyIllu_v10.safetensors' completed. Took 38 sec.\u001b[0m\n",
            "\u001b[0m\u001b[0;32m================================================================================\u001b[0m\n",
            "\u001b[0m\u001b[38;2;255;204;0m [-] Downloading Custom vae...\u001b[0m\n",
            "\u001b[0m\u001b[0;32m================================================================================\u001b[0m\n",
            "\u001b[0m\u001b[0;32mStarting download of 'sdxl.vae.safetensors' with aria2c...\u001b[0m\n",
            "\u001b[0m\u001b[0;32mDownload of 'sdxl.vae.safetensors' completed. Took 2 sec.\u001b[0m\n",
            "\u001b[0m\u001b[0;32m================================================================================\u001b[0m\n",
            "\u001b[0m\u001b[38;2;255;204;0mDownload finished. Took 1 mins 24 sec.\u001b[0m\n",
            "\u001b[0m\u001b[0;32m================================================================================\u001b[0m\n",
            "\u001b[0m\u001b[38;2;255;204;0mLaunching 'lllyasviel/stable-diffusion-webui-forge'\u001b[0m\n",
            "\u001b[0m\u001b[0;32m================================================================================\u001b[0m\n",
            "\u001b[0m\u001b[0;32mSelected VAE: sdxl.vae.safetensors\u001b[0m\n",
            "\u001b[0m\u001b[0;32m================================================================================\u001b[0m\n",
            "\u001b[0m\u001b[0m\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# @title ## (1) **Install Environment**\n",
        "import sys\n",
        "import subprocess\n",
        "import os\n",
        "import time\n",
        "import json\n",
        "import shutil\n",
        "import random\n",
        "import string\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "from pydantic import BaseModel\n",
        "import zipfile\n",
        "\n",
        "requirements_file = \"\"\"\n",
        "GitPython==3.1.32\n",
        "accelerate\n",
        "blendmodes==2022\n",
        "clean-fid==0.1.35\n",
        "diskcache==5.6.3\n",
        "einops\n",
        "facexlib==0.3.0\n",
        "fastapi==0.104.1\n",
        "gradio==4.40.0\n",
        "httpcore==0.15\n",
        "inflection==0.5.1\n",
        "jsonmerge==1.8.0\n",
        "kornia==0.6.7\n",
        "lark==1.1.2\n",
        "numpy\n",
        "omegaconf==2.2.3\n",
        "open-clip-torch==2.20.0\n",
        "piexif==1.1.3\n",
        "protobuf\n",
        "psutil==5.9.5\n",
        "pytorch_lightning==1.9.4\n",
        "resize-right==0.0.2\n",
        "safetensors\n",
        "scikit-image\n",
        "spandrel==0.3.4\n",
        "spandrel-extra-arches==0.1.1\n",
        "tomesd==0.1.3\n",
        "torchdiffeq==0.2.3\n",
        "torchsde==0.2.6\n",
        "transformers==4.46.1\n",
        "httpx==0.24.1\n",
        "pillow-avif-plugin==1.4.3\n",
        "diffusers==0.31.0\n",
        "gradio_rangeslider==0.0.6\n",
        "gradio_imageslider==0.0.20\n",
        "loadimg==0.1.2\n",
        "tqdm==4.66.1\n",
        "peft\n",
        "pydantic==2.8.2\n",
        "huggingface-hub==0.26.2\n",
        "peft==0.12.0\n",
        "pillow\n",
        "\"\"\"\n",
        "\n",
        "python_version  = \".\".join(sys.version.split(\".\")[:2])\n",
        "python_path     = Path(f\"/usr/local/lib/python{python_version}/dist-packages/\")\n",
        "colablib_path   = python_path / \"colablib\"\n",
        "if not colablib_path.exists():\n",
        "    subprocess.run(['pip', 'install', '--upgrade', 'git+https://github.com/Linaqruf/colablib'], check=True)\n",
        "\n",
        "from colablib.colored_print import cprint, print_line\n",
        "from colablib.utils import py_utils, package_utils, config_utils\n",
        "from colablib.sd_models.downloader import aria2_download, download\n",
        "from colablib.utils.git_utils import update_repo, reset_repo, validate_repo, batch_update\n",
        "from colablib.utils.py_utils import get_filename\n",
        "\n",
        "################################\n",
        "# COLAB ARGUMENTS GOES HERE\n",
        "################################\n",
        "\n",
        "# It ain't much, but it's honest work.\n",
        "class CustomDirs(BaseModel):\n",
        "    url: str\n",
        "    dst: str\n",
        "\n",
        "# @markdown ### **Drive Config**\n",
        "mount_drive          = True  # @param {type: 'boolean'}\n",
        "output_drive_folder  = \"android-colab-forge\"  # @param {type: 'string'}\n",
        "\n",
        "# @markdown ### **Repo Config**\n",
        "update_webui         = True  # @param {type: 'boolean'}\n",
        "update_extensions    = True  # @param {type: 'boolean'}\n",
        "commit_hash          = \"\"  # @param {type: 'string'}\n",
        "\n",
        "# @markdown ### **Download Config**\n",
        "# @markdown > Check only the options you need\n",
        "animagine_xl_3_1     = False  # @param {type: 'boolean'}\n",
        "rae_diffusion_xl_v2  = False  # @param {type: 'boolean'}\n",
        "kivotos_xl_v2_0      = False  # @param {type: 'boolean'}\n",
        "urangdiffusion_2_0   = False  # @param {type: 'boolean'}\n",
        "\n",
        "# @markdown - The following models require Civitai token\n",
        "wai_nsfw_illustrious_sdxl = False  # @param {type: 'boolean'}\n",
        "illustrious_xl_smoothft = False  # @param {type: 'boolean'}\n",
        "madly_mix_ver_nightnoob = False  # @param {type: 'boolean'}\n",
        "hassaku_xl_illustrious = False  # @param {type: 'boolean'}\n",
        "\n",
        "# @markdown - You will need to set Diffusion in Low Bits to bnb nf4 (fp16 Lora) for the following model\n",
        "flux1_dev_bnb_nf4    = False  # @param {type: 'boolean'}\n",
        "\n",
        "# @markdown ### **Miscellaneous Loras**\n",
        "# @markdown > Check only the options you need (Also need Civitai token)\n",
        "schnell_lora_for_flux1dev = False  # @param {type: 'boolean'}\n",
        "\n",
        "# @markdown > **Note:**\n",
        "# @markdown - For multiple URLs, use comma separation (e.g. `url1, url2, url3`)\n",
        "# @markdown - Forge supports FLUX, SD, and SDXL\n",
        "# @markdown - **Highly Recommended:** Use Hugging Face links whenever possible (Click the \"Copy Download Link\" button on the model page)\n",
        "# @markdown - **For civitai models**: Right click the download button and paste that link, but for some models you will need your civitai token, so include it below.\n",
        "civitai_token        = \"3dea9dc984c445eb902dd4ec6f3bca4d\"  # @param {type: 'string'}\n",
        "custom_model_url     = \"https://civitai.com/api/download/models/2514310?type=Model&format=SafeTensor&size=pruned&fp=fp16, https://civitai.com/api/download/models/2343145?type=Model&format=SafeTensor&size=pruned&fp=fp16\"  # @param {'type': 'string'}\n",
        "custom_vae_url       = \"https://huggingface.co/madebyollin/sdxl-vae-fp16-fix/resolve/main/sdxl.vae.safetensors\"  # @param {'type': 'string'}\n",
        "custom_lora_url      = \"\"  # @param {'type': 'string'}\n",
        "custom_upscaler_url   = \"\"  # @param {'type': 'string'}\n",
        "\n",
        "# @markdown ### **Custom Extensions**\n",
        "# @markdown > Enter the GitHub URLs for the extensions you want to install, separated by commas.\n",
        "custom_extensions_url = \"\"  # @param {type: 'string'}\n",
        "\n",
        "# @markdown ### **Custom ADetailer Models**\n",
        "# @markdown > Enter the URLs for the ADetailer models you want to download, separated by commas.\n",
        "custom_adetailer_url = \"https://civitai.com/api/download/models/1780243?type=Archive&format=Other\"  # @param {type: 'string'}\n",
        "\n",
        "# @markdown ### **If you have a lora folder in your drive, you can set it here, and it will add the loras to the lora folder**\n",
        "# @markdown > **Note:** This will not download the loras, it will just add them to the lora folder\n",
        "# @markdown - load_recursively: If checked, it will load all the loras in the folder and subfolders\n",
        "custom_lora_dir     = \"\"  # @param {'type': 'string'}\n",
        "load_recursively    = True  # @param {type: 'boolean'}\n",
        "\n",
        "# @markdown ### **Tunnel Config**\n",
        "# @markdown > Default to `--share` until `ngrok_token` is not `None`\n",
        "ngrok_token          = \"\"  # @param {type: 'string'}\n",
        "ngrok_region         = \"us\"  # @param [\"us\", \"eu\", \"au\", \"ap\", \"sa\", \"jp\", \"in\"]\n",
        "\n",
        "# @markdown ### **UI/UX Config**\n",
        "gradio_theme         = \"remilia/Ghostly\"  # @param [\"Default\", \"gradio/base\", \"gradio/glass\", \"gradio/monochrome\", \"gradio/seafoam\", \"gradio/soft\", \"gradio/dracula_test\", \"abidlabs/dracula_test\", \"abidlabs/Lime\", \"abidlabs/pakistan\", \"Ama434/neutral-barlow\", \"dawood/microsoft_windows\", \"finlaymacklon/smooth_slate\", \"Franklisi/darkmode\", \"freddyaboulton/dracula_revamped\", \"freddyaboulton/test-blue\", \"gstaff/xkcd\", \"Insuz/Mocha\", \"Insuz/SimpleIndigo\", \"JohnSmith9982/small_and_pretty\", \"nota-ai/theme\", \"nuttea/Softblue\", \"ParityError/Anime\", \"reilnuud/polite\", \"remilia/Ghostly\", \"rottenlittlecreature/Moon_Goblin\", \"step-3-profit/Midnight-Deep\", \"Taithrah/Minimal\", \"ysharma/huggingface\", \"ysharma/steampunk\", \"NoCrypt/miku\"]\n",
        "# @markdown Set `use_preset` for using default prompt, resolution, sampler, and other settings\n",
        "use_presets          = True  # @param {type: 'boolean'}\n",
        "\n",
        "# @markdown ### **Launch Arguments**\n",
        "use_gradio_auth      = False  # @param {type: 'boolean'}\n",
        "auto_select_model    = False  # @param {type: 'boolean'}\n",
        "auto_select_vae      = True  # @param {type: 'boolean'}\n",
        "additional_arguments = \"--lowram --theme dark --no-half-vae --opt-sdp-attention\"  # @param {type: 'string'}\n",
        "\n",
        "################################\n",
        "# GLOBAL VARIABLES GOES HERE\n",
        "################################\n",
        "\n",
        "# GRADIO AUTH\n",
        "user      = \"android\"\n",
        "password  = \"\".join(random.choices(string.ascii_letters + string.digits, k=6))\n",
        "\n",
        "# ROOT DIR\n",
        "root_dir        = Path(\"/content\")\n",
        "drive_dir       = root_dir / \"drive\" / \"MyDrive\"\n",
        "repo_dir        = root_dir / \"stable-diffusion-webui-forge\"\n",
        "tmp_dir         = root_dir / \"tmp\"\n",
        "\n",
        "models_dir      = repo_dir / \"models\"\n",
        "extensions_dir  = repo_dir / \"extensions\"\n",
        "ckpt_dir        = models_dir / \"Stable-diffusion\"\n",
        "vae_dir         = models_dir / \"VAE\"\n",
        "lora_dir        = models_dir / \"Lora\"\n",
        "output_subdir   = [\"txt2img-samples\", \"img2img-samples\", \"extras-samples\", \"txt2img-grids\", \"img2img-grids\"]\n",
        "\n",
        "config_file_path    = repo_dir / \"config.json\"\n",
        "ui_config_file_path = repo_dir / \"ui-config.json\"\n",
        "\n",
        "package_url = [\n",
        "    \"https://huggingface.co/Linaqruf/fast-repo/resolve/main/webui-forge.tar.lz4\",\n",
        "    \"https://huggingface.co/Linaqruf/fast-repo/resolve/main/webui-forge-deps.tar.lz4\"\n",
        "]\n",
        "\n",
        "custom_dirs = {\n",
        "    \"model\" : CustomDirs(url=custom_model_url, dst=str(ckpt_dir)),\n",
        "    \"vae\"   : CustomDirs(url=custom_vae_url, dst=str(vae_dir)),\n",
        "    \"lora\"  : CustomDirs(url=custom_lora_url, dst=str(lora_dir)),\n",
        "}\n",
        "\n",
        "default_model_urls = {\n",
        "    \"animagine_xl_3_1\"         : \"https://huggingface.co/cagliostrolab/animagine-xl-3.1/resolve/main/animagine-xl-3.1.safetensors\",\n",
        "    \"rae_diffusion_xl_v2\"      : \"https://huggingface.co/Raelina/Rae-Diffusion-XL-V2/resolve/main/RaeDiffusion-XL-v2.safetensors\",\n",
        "    \"kivotos_xl_v2_0\"          : \"https://huggingface.co/yodayo-ai/kivotos-xl-2.0/resolve/main/kivotos-xl-2.0.safetensors\",\n",
        "    \"urangdiffusion_2_0\"       : \"https://huggingface.co/kayfahaarukku/UrangDiffusion-2.0/resolve/main/UrangDiffusion-2.0.safetensors\",\n",
        "    \"wai_nsfw_illustrious_sdxl\": \"https://civitai.com/api/download/models/1490781?type=Model&format=SafeTensor&size=pruned&fp=fp16\",\n",
        "    \"illustrious_xl_smoothft\"  : \"https://civitai.com/api/download/models/1015877?type=Model&format=SafeTensor&size=pruned&fp=fp16\",\n",
        "    \"madly_mix_ver_nightnoob\"  : \"https://civitai.com/api/download/models/1202045?type=Model&format=SafeTensor&size=full&fp=fp16\",\n",
        "    \"hassaku_xl_illustrious\"   : \"https://civitai.com/api/download/models/1240288?type=Model&format=SafeTensor&size=pruned&fp=bf16\",\n",
        "    \"flux1_dev_bnb_nf4\"        : \"https://huggingface.co/lllyasviel/flux1-dev-bnb-nf4/blob/main/flux1-dev-bnb-nf4-v2.safetensors\"\n",
        "}\n",
        "\n",
        "default_lora_urls = {\n",
        "    \"schnell_lora_for_flux1dev\": \"https://civitai.com/api/download/models/759853?type=Model&format=SafeTensor\"\n",
        "}\n",
        "\n",
        "################################\n",
        "# HELPER FUNCTIONS STARTS HERE\n",
        "################################\n",
        "\n",
        "def mount_drive_function(directory):\n",
        "    output_dir = repo_dir / \"outputs\"\n",
        "\n",
        "    if mount_drive:\n",
        "        print_line(80, color=\"green\")\n",
        "        if not directory.exists():\n",
        "            from google.colab import drive\n",
        "\n",
        "            cprint(\"Mounting google drive...\", color=\"green\", reset=False)\n",
        "            drive.mount(str(directory.parent))\n",
        "        output_dir = directory / output_drive_folder\n",
        "        cprint(\"Set default output path to:\", output_dir, color=\"green\")\n",
        "\n",
        "    return output_dir\n",
        "\n",
        "def setup_directories():\n",
        "    for dir in [ckpt_dir, vae_dir, lora_dir]:\n",
        "        dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "def pre_download(dir, urls, desc, overwrite=False):\n",
        "    ffmpy_path = python_path / \"ffmpy-0.3.0.dist-info\"\n",
        "\n",
        "    for url in tqdm(urls, desc=desc):\n",
        "        filename = Path(url).name\n",
        "        aria2_download(dir, filename, url, quiet=True)\n",
        "        if filename == \"webui-forge-deps.tar.lz4\":\n",
        "            package_utils.extract_package(filename, python_path, overwrite=True)\n",
        "        else:\n",
        "            package_utils.extract_package(filename, \"/\", overwrite=overwrite)\n",
        "        os.remove(dir / filename)\n",
        "\n",
        "    subprocess.run([\"rm\", \"-rf\", str(ffmpy_path)])\n",
        "    subprocess.run([\"pip\", \"install\", \"--force-reinstall\", \"ffmpy\"], check=True)\n",
        "\n",
        "def install_dependencies():\n",
        "    # Added p7zip-full for rar/7z extraction\n",
        "    ubuntu_deps = [\"aria2\", \"lz4\", \"p7zip-full\"]\n",
        "    cprint(\"Installing ubuntu dependencies\", color=\"green\")\n",
        "    subprocess.run([\"apt\", \"install\", \"-y\"] + ubuntu_deps, check=True)\n",
        "\n",
        "def install_webui(repo_dir, desc):\n",
        "    if not repo_dir.exists():\n",
        "        pre_download(root_dir, package_url, desc, overwrite=False)\n",
        "\n",
        "    else:\n",
        "        cprint(\"Stable Diffusion Web UI forge already installed, skipping...\", color=\"green\")\n",
        "\n",
        "def configure_output_path(config_path, output_dir, output_subdir):\n",
        "    try:\n",
        "        config = config_utils.read_config(str(config_path))\n",
        "    except (FileNotFoundError, json.JSONDecodeError):\n",
        "        config = {}\n",
        "\n",
        "    config_updates = {\n",
        "        f\"outdir_{subdir.split('-')[0]}_{'_'.join(subdir.split('-')[1:])}\": str(output_dir / subdir)\n",
        "        for subdir in output_subdir\n",
        "    }\n",
        "\n",
        "    config.update(config_updates)\n",
        "\n",
        "    config_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    config_utils.write_config(str(config_path), config)\n",
        "\n",
        "    for dir in output_subdir:\n",
        "        (output_dir / dir).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "def prepare_environment():\n",
        "    cprint(\"Preparing environment...\", color=\"green\")\n",
        "    os.environ['PYTORCH_CUDA_ALLOC_CONF']   = \"garbage_collection_threshold:0.9,max_split_size_mb:512\"\n",
        "    os.environ[\"TF_CPP_MIN_LOG_LEVEL\"]      = \"3\"\n",
        "    os.environ[\"PYTHONWARNINGS\"]            = \"ignore\"\n",
        "\n",
        "def custom_download(custom_dirs):\n",
        "    filtered_urls = filter_dict_items(default_model_urls)\n",
        "    filtered_lora_urls = filter_dict_items(default_lora_urls)\n",
        "\n",
        "    for key, value in custom_dirs.items():\n",
        "        urls = value.url.split(\",\")\n",
        "        dst = value.dst\n",
        "\n",
        "        if key == \"model\":\n",
        "            urls.extend(filtered_urls)\n",
        "\n",
        "        if key == \"lora\":\n",
        "            urls.extend(filtered_lora_urls)\n",
        "\n",
        "        if urls[0]:\n",
        "            print_line(80, color=\"green\")\n",
        "            cprint(f\" [-] Downloading Custom {key}...\", color=\"flat_yellow\")\n",
        "\n",
        "        for url in urls:\n",
        "            if \"civitai.com\" in url:\n",
        "                if civitai_token:\n",
        "                    url = f\"{url}&token={civitai_token}\"\n",
        "                else:\n",
        "                    cprint(f\"Civitai token is required for this model {url}, skipping...\", color=\"red\")\n",
        "                    continue\n",
        "            url = url.strip()\n",
        "            if url != \"\":\n",
        "                print_line(80, color=\"green\")\n",
        "                if \"|\" in url:\n",
        "                    url, filename = map(str.strip, url.split(\"|\"))\n",
        "                    if not filename.endswith((\".safetensors\", \".ckpt\", \".pt\", \"pth\")):\n",
        "                        filename = filename + Path(get_filename(url)).suffix\n",
        "                else:\n",
        "                    filename = get_filename(url)\n",
        "\n",
        "                download(url=url, filename=filename, dst=dst, quiet=False)\n",
        "\n",
        "def filter_dict_items(dict_items):\n",
        "    result_list = []\n",
        "    for key, url in dict_items.items():\n",
        "        if globals().get(key):\n",
        "            result_list.append(url)\n",
        "    return result_list\n",
        "\n",
        "def auto_select_file(target_dir, config_key, file_types):\n",
        "    valid_files = [f for f in os.listdir(target_dir) if f.endswith(file_types)]\n",
        "    if valid_files:\n",
        "        file_path = random.choice(valid_files)\n",
        "\n",
        "        if Path(target_dir).joinpath(file_path).exists():\n",
        "            config = config_utils.read_config(str(config_file_path))\n",
        "            config[config_key] = file_path\n",
        "            config_utils.write_config(str(config_file_path), config)\n",
        "        return file_path\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "def ui_config_presets():\n",
        "    preset_prompt = \"masterpiece, best quality, very aesthetic, absurdres\"\n",
        "    preset_negative_prompt = \"nsfw, lowres, (bad), text, error, fewer, extra, missing, worst quality, jpeg artifacts, low quality, watermark, unfinished, displeasing, oldest, early, chromatic aberration, signature, extra digits, artistic error, username, scan, [abstract]\"\n",
        "\n",
        "    return {\n",
        "        \"txt2img/Prompt/value\"              : preset_prompt,\n",
        "        \"txt2img/Negative prompt/value\"     : preset_negative_prompt,\n",
        "        \"img2img/Prompt/value\"              : preset_prompt,\n",
        "        \"img2img/Negative prompt/value\"     : preset_negative_prompt,\n",
        "        \"customscript/sampler.py/txt2img/Sampling method/value\" : \"Euler a\",\n",
        "        \"customscript/sampler.py/txt2img/Sampling steps/value\"  : 28,\n",
        "        \"customscript/sampler.py/txt2img/Scheduler/value\"       : \"Automatic\",\n",
        "    }\n",
        "\n",
        "def ui_config_settings(ui_config_file: str):\n",
        "    config = config_utils.read_config(str(ui_config_file))\n",
        "    preset_config = ui_config_presets()\n",
        "\n",
        "    for key, value in preset_config.items():\n",
        "        config[key] = value\n",
        "\n",
        "    config_utils.write_config(str(ui_config_file), config)\n",
        "\n",
        "def general_config_presets(config_file: str, lora_dir: str, use_presets: bool, ui_config_file: str):\n",
        "    config = config_utils.read_config(str(config_file))\n",
        "\n",
        "    config.update({\n",
        "        \"CLIP_stop_at_last_layers\"      : 2,\n",
        "        \"show_progress_every_n_steps\"   : 10,\n",
        "        \"show_progressbar\"              : True,\n",
        "        \"samples_filename_pattern\"      : \"[model_name]_[seed]\",\n",
        "        \"show_progress_type\"            : \"Approx NN\",\n",
        "        \"live_preview_content\"          : \"Prompt\",\n",
        "        \"forge_preset\"                  : \"xl\",\n",
        "        \"xl_t2i_width\"                  : 832,\n",
        "        \"xl_t2i_height\"                 : 1216,\n",
        "        \"xl_t2i_cfg\"                    : 5.5,\n",
        "        \"xl_t2i_hr_cfg\"                 : 7,\n",
        "        \"xl_t2i_sampler\"                : \"Euler a\",\n",
        "        \"xl_t2i_scheduler\"              : \"Automatic\",\n",
        "        \"gradio_theme\"                  : gradio_theme,\n",
        "    })\n",
        "\n",
        "    config_utils.write_config(str(config_file), config)\n",
        "\n",
        "    if use_presets:\n",
        "        ui_config_settings(ui_config_file)\n",
        "\n",
        "def is_valid(target_dir, file_types):\n",
        "    return any(f.endswith(file_types) for f in os.listdir(target_dir))\n",
        "\n",
        "def parse_args(config):\n",
        "    args = []\n",
        "    for k, v in config.items():\n",
        "        if k.startswith(\"_\"):\n",
        "            args.append(f'\"{v}\"')\n",
        "        elif isinstance(v, str):\n",
        "            args.append(f'--{k}=\"{v}\"')\n",
        "        elif isinstance(v, bool) and v:\n",
        "            args.append(f\"--{k}\")\n",
        "        elif isinstance(v, (float, int)) and not isinstance(v, bool):\n",
        "            args.append(f\"--{k}={v}\")\n",
        "    return \" \".join(args)\n",
        "\n",
        "def main():\n",
        "    global output_dir, auto_select_model, auto_select_vae, final_args\n",
        "\n",
        "    ################################\n",
        "    # MAIN EXECUTION\n",
        "    ################################\n",
        "\n",
        "    os.chdir(root_dir)\n",
        "    start_time = time.time()\n",
        "    output_dir = mount_drive_function(drive_dir)\n",
        "\n",
        "    gpu_info    = py_utils.get_gpu_info(get_gpu_name=True)\n",
        "    python_info = py_utils.get_python_version()\n",
        "    torch_info  = py_utils.get_torch_version()\n",
        "\n",
        "    print_line(80, color=\"green\")\n",
        "    cprint(f\" [-] Current GPU: {gpu_info}\", color=\"flat_yellow\")\n",
        "    cprint(f\" [-] Python {python_info}\", color=\"flat_yellow\")\n",
        "    cprint(f\" [-] Torch {torch_info}\", color=\"flat_yellow\")\n",
        "    print_line(80, color=\"green\")\n",
        "\n",
        "    try:\n",
        "        install_dependencies()\n",
        "\n",
        "        print_line(80, color=\"green\")\n",
        "        install_webui(repo_dir, cprint(\"Unpacking Web UI forge\", color=\"green\", tqdm_desc=True))\n",
        "        prepare_environment()\n",
        "\n",
        "        configure_output_path(config_file_path, output_dir, output_subdir)\n",
        "\n",
        "        print_line(80, color=\"green\")\n",
        "        if update_webui and not commit_hash:\n",
        "            update_repo(cwd=repo_dir, args=\"-X theirs --rebase --autostash\")\n",
        "        elif commit_hash:\n",
        "            reset_repo(repo_dir, commit_hash)\n",
        "\n",
        "        setup_directories()\n",
        "\n",
        "        repo_name, current_commit_hash, current_branch = validate_repo(repo_dir)\n",
        "        cprint(f\"Using '{repo_name}' repository...\", color=\"green\")\n",
        "        cprint(f\"Branch: {current_branch}, Commit hash: {current_commit_hash}\", color=\"green\")\n",
        "\n",
        "        if update_extensions:\n",
        "            print_line(80, color=\"green\")\n",
        "            batch_update(fetch=True, directory=extensions_dir, desc=cprint(\"Updating extensions\", color=\"green\", tqdm_desc=True))\n",
        "\n",
        "\n",
        "        # addding adetailer\n",
        "        print_line(80, color=\"green\")\n",
        "        cprint(\"Installing ADetailer Reforge...\", color=\"green\")\n",
        "        if not Path(extensions_dir / \"aadetailer-reforge\").exists():\n",
        "            !git clone https://github.com/Anzhc/aadetailer-reforge.git {extensions_dir / \"aadetailer-reforge\"}\n",
        "        else:\n",
        "            cprint(\"ADetailer Reforge already installed, skipping...\", color=\"green\")\n",
        "\n",
        "        # Added Anzhc Yolo models to adetailer (by placing it in models/adetailer)\n",
        "        print_line(80, color=\"green\")\n",
        "        cprint(\"Installing Adetailer/Yolo models...\", color=\"green\")\n",
        "        anzhc_models = [\"https://huggingface.co/Anzhc/Anzhcs_YOLOs/blob/main/Anzhc%20Breasts%20Seg%20v1%201024m.pt\",\n",
        "                        \"https://huggingface.co/Anzhc/Anzhcs_YOLOs/blob/main/Anzhc%20Eyes%20-seg-hd.pt\",\n",
        "                        \"https://huggingface.co/Anzhc/Anzhcs_YOLOs/blob/main/Anzhc%20Face%20-seg.pt\",\n",
        "                        \"https://huggingface.co/Anzhc/Anzhcs_YOLOs/blob/main/Anzhc%20Face%20seg%201024%20v2%20y8n.pt\",\n",
        "                        \"https://huggingface.co/Anzhc/Anzhcs_YOLOs/blob/main/Anzhc%20HeadHair%20seg%20y8m.pt\",\n",
        "                        \"https://huggingface.co/Anzhc/Anzhcs_YOLOs/blob/main/Anzhc%20Manga%20Panels%20-seg.pt\",\n",
        "                        \"https://huggingface.co/Anzhc/Anzhcs_YOLOs/blob/main/Anzhcs%20ManFace%20v02%201024%20y8n.pt\",\n",
        "                        \"https://huggingface.co/Anzhc/Anzhcs_YOLOs/blob/main/Anzhcs%20WomanFace%20v05%201024%20y8n.pt\",\n",
        "                        \"https://huggingface.co/Bingsu/adetailer/resolve/main/hand_yolov9c.pt\",\n",
        "                        \"https://huggingface.co/MonetEinsley/ADetailer_CM/resolve/main/foot_yolov8x_v2.pt\"]\n",
        "\n",
        "        for url in anzhc_models:\n",
        "            # if the file is not found, download it\n",
        "            if not Path(models_dir / \"adetailer\" / get_filename(url)).exists():\n",
        "                download(url=url, filename=get_filename(url), dst=str(models_dir / \"adetailer\"), quiet=False)\n",
        "            else:\n",
        "                cprint(f\"Model {get_filename(url)} already exists, skipping...\", color=\"green\")\n",
        "\n",
        "        # Downloading custom adetailer models\n",
        "        if custom_adetailer_url:\n",
        "            print_line(80, color=\"green\")\n",
        "            cprint(\"Downloading Custom ADetailer Models...\", color=\"green\")\n",
        "            for url in custom_adetailer_url.split(\",\"):\n",
        "                url = url.strip()\n",
        "                if not url: continue\n",
        "\n",
        "                # Check for civitai and token\n",
        "                if \"civitai.com\" in url:\n",
        "                    if civitai_token:\n",
        "                        if \"?\" in url:\n",
        "                             url = f\"{url}&token={civitai_token}\"\n",
        "                        else:\n",
        "                             url = f\"{url}?token={civitai_token}\"\n",
        "                    else:\n",
        "                        cprint(f\"Civitai URL detected but no token provided: {url}\", color=\"yellow\")\n",
        "\n",
        "                filename = get_filename(url)\n",
        "                dst_path = models_dir / \"adetailer\"\n",
        "                downloaded_file_path = dst_path / filename\n",
        "\n",
        "                # We skip if the exact filename exists, OR if we previously extracted it (difficult to know without tracking, so we rely on file existence)\n",
        "                if downloaded_file_path.exists():\n",
        "                     cprint(f\"File {filename} already exists, skipping...\", color=\"green\")\n",
        "                     continue\n",
        "\n",
        "                try:\n",
        "                    download(url=url, filename=filename, dst=str(dst_path), quiet=False)\n",
        "\n",
        "                    # Check if extraction is needed\n",
        "                    if filename.lower().endswith(('.zip', '.rar', '.7z')):\n",
        "                         cprint(f\"Extracting {filename}...\", color=\"green\")\n",
        "                         # Use 7z for extraction (covers zip, rar, 7z)\n",
        "                         # -y assumes yes to all queries (overwrite)\n",
        "                         # -o specifies output directory\n",
        "                         subprocess.run([\"7z\", \"x\", str(downloaded_file_path), f\"-o{str(dst_path)}\", \"-y\"], check=True)\n",
        "\n",
        "                         # Remove the archive after extraction\n",
        "                         os.remove(downloaded_file_path)\n",
        "                         cprint(f\"Extracted and removed archive: {filename}\", color=\"green\")\n",
        "\n",
        "                    cprint(f\"{filename} Adetailer model has been downloaded\", color=\"flat_yellow\")\n",
        "\n",
        "                except Exception as e:\n",
        "                    cprint(f\"Failed to download or extract {url}: {e}\", color=\"red\")\n",
        "\n",
        "\n",
        "        # Adding Upscalers to models/ESRGAN\n",
        "        print_line(80, color=\"green\")\n",
        "        cprint(\"Installing ESRGAN models...\", color=\"green\")\n",
        "        esrgan_models = [\"https://huggingface.co/Kim2091/AnimeSharp/blob/main/4x-AnimeSharp.safetensors\",\n",
        "                        \"https://huggingface.co/Kim2091/UltraSharp/resolve/main/4x-UltraSharp.pth?download=true\"\n",
        "                         ]\n",
        "\n",
        "        esrgan_models.extend([i for i in esrgan_models if i])\n",
        "\n",
        "        for url in esrgan_models:\n",
        "            if not Path(models_dir / \"ESRGAN\" / get_filename(url)).exists():\n",
        "                download(url=url, filename=get_filename(url), dst=str(models_dir / \"ESRGAN\"), quiet=False)\n",
        "            else:\n",
        "                cprint(f\"Model {get_filename(url)} already exists, skipping...\", color=\"green\")\n",
        "\n",
        "        # adding civitai downloader\n",
        "        print_line(80, color=\"green\")\n",
        "        cprint(\"Installing Civitai Downloader...\", color=\"green\")\n",
        "        civitai_downloader_dir = extensions_dir / \"sd-webui-civitai-downloader\"\n",
        "\n",
        "        if not civitai_downloader_dir.exists():\n",
        "            !git clone https://github.com/otacoo/sd-webui-civitai-downloader.git {civitai_downloader_dir}\n",
        "        else:\n",
        "            cprint(\"Civitai Downloader already installed, skipping...\", color=\"green\")\n",
        "\n",
        "        # adding SD Forge Couple\n",
        "        print_line(80, color=\"green\")\n",
        "        cprint(\"Installing SD Forge Couple...\", color=\"green\")\n",
        "        sd_forge_couple_dir = extensions_dir / \"sd-forge-couple\"\n",
        "\n",
        "        if not sd_forge_couple_dir.exists():\n",
        "            !git clone https://github.com/Haoming02/sd-forge-couple {sd_forge_couple_dir}\n",
        "        else:\n",
        "            cprint(\"SD Forge Couple already installed, skipping...\", color=\"green\")\n",
        "\n",
        "        # installing custom extensions\n",
        "        if custom_extensions_url:\n",
        "            print_line(80, color=\"green\")\n",
        "            cprint(\"Installing Custom Extensions...\", color=\"green\")\n",
        "            for url in custom_extensions_url.split(\",\"):\n",
        "                url = url.strip()\n",
        "                if not url: continue\n",
        "                repo_name = url.split(\"/\")[-1].replace(\".git\", \"\")\n",
        "                ext_path = extensions_dir / repo_name\n",
        "\n",
        "                if not ext_path.exists():\n",
        "                    cprint(f\"Cloning {repo_name}...\", color=\"green\")\n",
        "                    try:\n",
        "                        subprocess.run([\"git\", \"clone\", url, str(ext_path)], check=True)\n",
        "                    except subprocess.CalledProcessError:\n",
        "                        cprint(f\"Failed to clone {repo_name}\", color=\"red\")\n",
        "                else:\n",
        "                    cprint(f\"Extension {repo_name} already installed, skipping...\", color=\"green\")\n",
        "\n",
        "        elapsed_time = py_utils.calculate_elapsed_time(start_time)\n",
        "        print_line(80, color=\"green\")\n",
        "\n",
        "        # adding loras from custom lora directory\n",
        "        print_line(80, color=\"green\")\n",
        "        cprint(f\"Installing custom loras from '{custom_lora_dir}'\", color=\"green\")\n",
        "        lora_count = 0\n",
        "        if custom_lora_dir:\n",
        "            if load_recursively:\n",
        "                custom_lora_path = Path(custom_lora_dir)\n",
        "                for root, dirs, files in os.walk(custom_lora_path):\n",
        "                    for file in files:\n",
        "                        if file.endswith((\".ckpt\", \".safetensors\", \".pt\")):\n",
        "                            src_path = Path(root) / file\n",
        "                            dst_path = lora_dir / file\n",
        "\n",
        "                            # check if the file already exists\n",
        "                            if dst_path.exists():\n",
        "                                # if the file exists, skip it\n",
        "                                cprint(f\"File {dst_path} already exists, skipping...\", color=\"yellow\")\n",
        "                                continue\n",
        "                            else:\n",
        "                                # if the file doesn't exist, copy it\n",
        "                                cprint(f\"Adding {file}\", color=\"green\")\n",
        "\n",
        "                            shutil.copy(src_path, dst_path)\n",
        "                            lora_count += 1\n",
        "            else:\n",
        "                custom_lora_path = Path(custom_lora_dir)\n",
        "                if not lora_dir.exists():\n",
        "                    cprint(f\"Custom lora directory {lora_dir} does not exist, skipping...\", color=\"red\")\n",
        "                    return\n",
        "                for file in os.listdir(custom_lora_path):\n",
        "                    if file.endswith((\".ckpt\", \".safetensors\", \".pt\")):\n",
        "                        src_path = custom_lora_path / file\n",
        "                        dst_path = lora_dir / file\n",
        "\n",
        "                        # check if the file already exists\n",
        "                        if dst_path.exists():\n",
        "                            # if the file exists, skip it\n",
        "                            cprint(f\"File {dst_path} already exists, skipping...\", color=\"yellow\")\n",
        "                            continue\n",
        "                        else:\n",
        "                            # if the file doesn't exist, copy it\n",
        "                            cprint(f\"Adding {file}\", color=\"green\")\n",
        "\n",
        "                        shutil.copy(src_path, dst_path)\n",
        "                        lora_count += 1\n",
        "\n",
        "        if lora_count == 0:\n",
        "            cprint(\"No loras found in the custom lora directory, skipping...\", color=\"red\")\n",
        "        else:\n",
        "            cprint(f\"Found {lora_count} loras in the custom lora directory.\", color=\"green\")\n",
        "        cprint(\"Installing custom loras finished.\", color=\"green\")\n",
        "\n",
        "        cprint(f\"Finished installation. Took {elapsed_time}.\", color=\"flat_yellow\")\n",
        "    except Exception as e:\n",
        "        cprint(f\"An error occurred: {str(e)}\", color=\"red\")\n",
        "        print_line(80, color=\"red\")\n",
        "        cprint(\"Setup failed. Please check the error message above and try again.\", color=\"red\")\n",
        "        print_line(80, color=\"red\")\n",
        "        return\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    custom_download(custom_dirs)\n",
        "\n",
        "    elapsed_time = py_utils.calculate_elapsed_time(start_time)\n",
        "    print_line(80, color=\"green\")\n",
        "    cprint(f\"Download finished. Took {elapsed_time}.\", color=\"flat_yellow\")\n",
        "    print_line(80, color=\"green\")\n",
        "    cprint(f\"Launching '{repo_name}'\", color=\"flat_yellow\")\n",
        "    print_line(80, color=\"green\")\n",
        "\n",
        "    if not is_valid(ckpt_dir, ('.ckpt', '.safetensors')):\n",
        "        cprint(f\"No checkpoints were found in the directory '{ckpt_dir}'.\", color=\"yellow\")\n",
        "        url = \"https://huggingface.co/cagliostrolab/animagine-xl-3.1/blob/main/animagine-xl-3.1.safetensors\"\n",
        "        filename = get_filename(url)\n",
        "        aria2_download(url=url, download_dir=ckpt_dir, filename=filename)\n",
        "        print_line(80, color=\"green\")\n",
        "        auto_select_model = True\n",
        "\n",
        "    if not is_valid(vae_dir, ('.vae.pt', '.vae.safetensors', '.pt', '.ckpt')):\n",
        "        cprint(f\"No VAEs were found in the directory '{vae_dir}'.\", color=\"yellow\")\n",
        "        url = \"https://huggingface.co/madebyollin/sdxl-vae-fp16-fix/blob/main/sdxl.vae.safetensors\"\n",
        "        filename = get_filename(url)\n",
        "        aria2_download(url=url, download_dir=vae_dir, filename=filename)\n",
        "        print_line(80, color=\"green\")\n",
        "        auto_select_vae = True\n",
        "\n",
        "    if auto_select_model:\n",
        "        selected_model  = auto_select_file(ckpt_dir, \"sd_model_checkpoint\", ('.ckpt', '.safetensors'))\n",
        "        cprint(f\"Selected Model: {selected_model}\", color=\"green\")\n",
        "\n",
        "    if auto_select_vae:\n",
        "        selected_vae    = auto_select_file(vae_dir, \"sd_vae\", ('.vae.pt', '.vae.safetensors', '.pt', '.ckpt'))\n",
        "        cprint(f\"Selected VAE: {selected_vae}\", color=\"green\")\n",
        "\n",
        "    # replacing faulty stuff\n",
        "    with open(repo_dir / \"requirements_versions.txt\", \"w\") as f:\n",
        "        f.write(requirements_file)\n",
        "    #  /content/stable-diffusion-webui-forge/extensions/sd-hub\n",
        "    !rm -rf {repo_dir / \"extensions/sd-hub\"}\n",
        "    print_line(80, color=\"green\")\n",
        "\n",
        "    general_config_presets(config_file_path, lora_dir, use_presets, ui_config_file_path)\n",
        "\n",
        "    if use_gradio_auth:\n",
        "      cprint(\"Gradio Auth (use this account to login):\", color=\"green\")\n",
        "      cprint(\"[-] Username: cagliostro\", color=\"green\")\n",
        "      cprint(\"[-] Password:\", password, color=\"green\")\n",
        "      print_line(80, color=\"green\")\n",
        "\n",
        "    config = {\n",
        "        \"enable-insecure-extension-access\": True,\n",
        "        \"disable-safe-unpickle\"           : True,\n",
        "        \"share\"                           : True if not ngrok_token else False,\n",
        "        \"ngrok\"                           : ngrok_token if ngrok_token else None,\n",
        "        \"ngrok-region\"                    : ngrok_region if ngrok_token else None,\n",
        "        \"gradio-auth\"                     : f\"{user}:{password}\" if use_gradio_auth else None,\n",
        "        \"no-hashing\"                      : False,\n",
        "        \"disable-console-progressbars\"    : True,\n",
        "        \"lowram\"                          : True,\n",
        "        \"opt-sub-quad-attention\"          : True,\n",
        "        \"opt-channelslast\"                : True,\n",
        "        \"no-download-sd-model\"            : True,\n",
        "        \"gradio-queue\"                    : True,\n",
        "        \"listen\"                          : True,\n",
        "        \"ckpt-dir\"                        : ckpt_dir,\n",
        "        \"vae-dir\"                         : vae_dir,\n",
        "        \"lora-dir\"                        : lora_dir,\n",
        "    }\n",
        "\n",
        "    args = parse_args(config)\n",
        "    final_args = f\"python launch.py {args} {additional_arguments}\"\n",
        "\n",
        "    cprint()\n",
        "    os.chdir(repo_dir)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "cellView": "form",
        "id": "NtomKGCHGtE5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f1ecc11b-6adf-4a7e-cb7c-bc65d7fcf2a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: pydantic 2.12.3\n",
            "Uninstalling pydantic-2.12.3:\n",
            "  Successfully uninstalled pydantic-2.12.3\n",
            "Found existing installation: fastapi 0.104.1\n",
            "Uninstalling fastapi-0.104.1:\n",
            "  Successfully uninstalled fastapi-0.104.1\n",
            "Found existing installation: starlette 0.27.0\n",
            "Uninstalling starlette-0.27.0:\n",
            "  Successfully uninstalled starlette-0.27.0\n",
            "Found existing installation: gradio 4.40.0\n",
            "Uninstalling gradio-4.40.0:\n",
            "  Successfully uninstalled gradio-4.40.0\n",
            "Found existing installation: pydantic-settings 2.12.0\n",
            "Uninstalling pydantic-settings-2.12.0:\n",
            "  Successfully uninstalled pydantic-settings-2.12.0\n",
            "Found existing installation: typing_extensions 4.15.0\n",
            "Uninstalling typing_extensions-4.15.0:\n",
            "  Successfully uninstalled typing_extensions-4.15.0\n",
            "Collecting pydantic>=2.1.1\n",
            "  Downloading pydantic-2.12.5-py3-none-any.whl.metadata (90 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.6/90.6 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fastapi>=0.100.0 in /usr/local/lib/python3.12/dist-packages (0.123.10)\n",
            "Requirement already satisfied: starlette>=0.27.0 in /usr/local/lib/python3.12/dist-packages (0.50.0)\n",
            "Collecting pydantic-settings>=1.0.0\n",
            "  Downloading pydantic_settings-2.12.0-py3-none-any.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: gradio>=3.55.0 in /usr/local/lib/python3.12/dist-packages (5.50.0)\n",
            "Collecting typing-extensions>=4.5.0\n",
            "  Downloading typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.1.1) (0.7.0)\n",
            "Collecting pydantic-core==2.41.5 (from pydantic>=2.1.1)\n",
            "  Downloading pydantic_core-2.41.5-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.1.1) (0.4.2)\n",
            "Requirement already satisfied: annotated-doc>=0.0.2 in /usr/local/lib/python3.12/dist-packages (from fastapi>=0.100.0) (0.0.4)\n",
            "Requirement already satisfied: anyio<5,>=3.6.2 in /usr/local/lib/python3.12/dist-packages (from starlette>=0.27.0) (4.12.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings>=1.0.0) (1.0.1)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.12/dist-packages (from gradio>=3.55.0) (23.2.1)\n",
            "Requirement already satisfied: brotli>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from gradio>=3.55.0) (1.2.0)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.12/dist-packages (from gradio>=3.55.0) (1.0.0)\n",
            "Collecting gradio-client==1.14.0 (from gradio>=3.55.0)\n",
            "  Downloading gradio_client-1.14.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.12/dist-packages (from gradio>=3.55.0) (0.1.2)\n",
            "Requirement already satisfied: httpx<1.0,>=0.24.1 in /usr/local/lib/python3.12/dist-packages (from gradio>=3.55.0) (0.24.1)\n",
            "Requirement already satisfied: huggingface-hub<2.0,>=0.33.5 in /usr/local/lib/python3.12/dist-packages (from gradio>=3.55.0) (0.36.0)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.12/dist-packages (from gradio>=3.55.0) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio>=3.55.0) (3.0.3)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.12/dist-packages (from gradio>=3.55.0) (2.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio>=3.55.0) (3.10.7)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from gradio>=3.55.0) (25.0)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.12/dist-packages (from gradio>=3.55.0) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.12/dist-packages (from gradio>=3.55.0) (9.5.0)\n",
            "Collecting pydantic>=2.1.1\n",
            "  Downloading pydantic-2.12.3-py3-none-any.whl.metadata (87 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.7/87.7 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydub in /usr/local/lib/python3.12/dist-packages (from gradio>=3.55.0) (0.25.1)\n",
            "Collecting python-multipart>=0.0.18 (from gradio>=3.55.0)\n",
            "  Downloading python_multipart-0.0.21-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.12/dist-packages (from gradio>=3.55.0) (6.0.3)\n",
            "Collecting ruff>=0.9.3 (from gradio>=3.55.0)\n",
            "  Downloading ruff-0.14.10-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (26 kB)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.12/dist-packages (from gradio>=3.55.0) (0.1.7)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio>=3.55.0) (2.10.0)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from gradio>=3.55.0) (0.12.0)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.12/dist-packages (from gradio>=3.55.0) (0.20.0)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.12/dist-packages (from gradio>=3.55.0) (0.31.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.14.0->gradio>=3.55.0) (2025.3.0)\n",
            "Collecting websockets<16.0,>=13.0 (from gradio-client==1.14.0->gradio>=3.55.0)\n",
            "  Downloading websockets-15.0.1-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.1.1) (2.41.4)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.6.2->starlette>=0.27.0) (3.11)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio>=3.55.0) (2025.11.12)\n",
            "Requirement already satisfied: httpcore<0.18.0,>=0.15.0 in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio>=3.55.0) (0.15.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio>=3.55.0) (1.3.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio>=3.55.0) (3.20.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio>=3.55.0) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio>=3.55.0) (4.67.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio>=3.55.0) (1.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio>=3.55.0) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio>=3.55.0) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio>=3.55.0) (2025.3)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio>=3.55.0) (8.3.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio>=3.55.0) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio>=3.55.0) (13.9.4)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.12/dist-packages (from uvicorn>=0.14.0->gradio>=3.55.0) (0.12.0)\n",
            "Collecting anyio<5,>=3.6.2 (from starlette>=0.27.0)\n",
            "  Downloading anyio-3.7.1-py3-none-any.whl.metadata (4.7 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio>=3.55.0) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio>=3.55.0) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio>=3.55.0) (2.19.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<2.0,>=0.33.5->gradio>=3.55.0) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<2.0,>=0.33.5->gradio>=3.55.0) (2.5.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio>=3.55.0) (0.1.2)\n",
            "Downloading pydantic_settings-2.12.0-py3-none-any.whl (51 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.9/51.9 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-1.14.0-py3-none-any.whl (325 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m325.6/325.6 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic-2.12.3-py3-none-any.whl (462 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m462.4/462.4 kB\u001b[0m \u001b[31m39.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_multipart-0.0.21-py3-none-any.whl (24 kB)\n",
            "Downloading ruff-0.14.10-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.2/14.2 MB\u001b[0m \u001b[31m123.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading anyio-3.7.1-py3-none-any.whl (80 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.9/80.9 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading websockets-15.0.1-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (182 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m182.5/182.5 kB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: websockets, typing-extensions, ruff, python-multipart, anyio, pydantic, pydantic-settings, gradio-client\n",
            "  Attempting uninstall: websockets\n",
            "    Found existing installation: websockets 12.0\n",
            "    Uninstalling websockets-12.0:\n",
            "      Successfully uninstalled websockets-12.0\n",
            "  Attempting uninstall: ruff\n",
            "    Found existing installation: ruff 0.6.9\n",
            "    Uninstalling ruff-0.6.9:\n",
            "      Successfully uninstalled ruff-0.6.9\n",
            "  Attempting uninstall: python-multipart\n",
            "    Found existing installation: python-multipart 0.0.12\n",
            "    Uninstalling python-multipart-0.0.12:\n",
            "      Successfully uninstalled python-multipart-0.0.12\n",
            "  Attempting uninstall: anyio\n",
            "    Found existing installation: anyio 4.12.0\n",
            "    Uninstalling anyio-4.12.0:\n",
            "      Successfully uninstalled anyio-4.12.0\n",
            "  Attempting uninstall: gradio-client\n",
            "    Found existing installation: gradio_client 1.2.0\n",
            "    Uninstalling gradio_client-1.2.0:\n",
            "      Successfully uninstalled gradio_client-1.2.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-adk 1.21.0 requires anyio<5.0.0,>=4.9.0, but you have anyio 3.7.1 which is incompatible.\n",
            "google-adk 1.21.0 requires uvicorn<1.0.0,>=0.34.0, but you have uvicorn 0.31.1 which is incompatible.\n",
            "firebase-admin 6.9.0 requires httpx[http2]==0.28.1, but you have httpx 0.24.1 which is incompatible.\n",
            "google-genai 1.55.0 requires anyio<5.0.0,>=4.8.0, but you have anyio 3.7.1 which is incompatible.\n",
            "google-genai 1.55.0 requires httpx<1.0.0,>=0.28.1, but you have httpx 0.24.1 which is incompatible.\n",
            "mcp 1.24.0 requires anyio>=4.5, but you have anyio 3.7.1 which is incompatible.\n",
            "mcp 1.24.0 requires httpx>=0.27.1, but you have httpx 0.24.1 which is incompatible.\n",
            "sse-starlette 3.0.4 requires anyio>=4.7.0, but you have anyio 3.7.1 which is incompatible.\n",
            "langgraph-sdk 0.3.0 requires httpx>=0.25.2, but you have httpx 0.24.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed anyio-3.7.1 gradio-client-1.14.0 pydantic-2.12.3 pydantic-settings-2.12.0 python-multipart-0.0.21 ruff-0.14.10 typing-extensions-4.15.0 websockets-15.0.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pydantic"
                ]
              },
              "id": "b68000a83eb2488393dd304a9caa8891"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (9.5.0)\n",
            "Collecting pillow\n",
            "  Downloading pillow-12.0.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (8.8 kB)\n",
            "Downloading pillow-12.0.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (7.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m86.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pillow\n",
            "  Attempting uninstall: pillow\n",
            "    Found existing installation: Pillow 9.5.0\n",
            "    Uninstalling Pillow-9.5.0:\n",
            "      Successfully uninstalled Pillow-9.5.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "blendmodes 2022 requires numpy<2,>=1.22.1, but you have numpy 2.0.2 which is incompatible.\n",
            "blendmodes 2022 requires Pillow<10,>=9.0.0, but you have pillow 12.0.0 which is incompatible.\n",
            "gradio 5.50.0 requires pillow<12.0,>=8.0, but you have pillow 12.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed pillow-12.0.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL"
                ]
              },
              "id": "6bc90f86c9784dd7bec385384d484cac"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "#@markdown ## (2) Run this cell before you start the webui (Only do it once), If you get a prompt to restart environment, just ignore it\n",
        "!pip uninstall -y pydantic fastapi starlette gradio pydantic-settings typing-extensions || true\n",
        "!pip install \"pydantic>=2.1.1\" \"fastapi>=0.100.0\" \"starlette>=0.27.0\" \"pydantic-settings>=1.0.0\" \"gradio>=3.55.0\" \"typing-extensions>=4.5.0\"\n",
        "!pip install -U pillow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "cellView": "form",
        "id": "UXbWBCg7FLf3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4bf8bef-011a-4bec-adc2-d6a3d4bc775f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=============================================================================================\n",
            "INCOMPATIBLE PYTHON VERSION\n",
            "\n",
            "This program is tested with 3.10.6 Python, but you have 3.12.12.\n",
            "If you encounter an error with \"RuntimeError: Couldn't install torch.\" message,\n",
            "or any other error regarding unsuccessful package (library) installation,\n",
            "please downgrade (or upgrade) to the latest version of 3.10 Python\n",
            "and delete current Python and \"venv\" folder in WebUI's directory.\n",
            "\n",
            "You can download 3.10 Python from here: https://www.python.org/downloads/release/python-3106/\n",
            "\n",
            "\n",
            "\n",
            "Use --skip-python-version-check to suppress this warning.\n",
            "=============================================================================================\n",
            "Python 3.12.12 (main, Oct 10 2025, 08:52:57) [GCC 11.4.0]\n",
            "Version: f2.0.1v1.10.1-previous-669-gdfdcbab6\n",
            "Commit hash: dfdcbab685e57677014f05a3309b48cc87383167\n",
            "Installing sd-webui-infinite-image-browsing requirement: av>=14,<15\n",
            "Couldn't install sd-webui-infinite-image-browsing requirement: av>=14,<15.\n",
            "Command: \"/usr/bin/python3\" -m pip install av>=14,<15 --prefer-binary\n",
            "Error code: 2\n",
            "stderr: /bin/sh: 1: cannot open 15: No such file\n",
            "\n",
            "Warning: Failed to install av>=14,<15, something may not work.\n",
            "Legacy Preprocessor init warning: Unable to install insightface automatically. Please try run `pip install insightface` manually.\n",
            "Launching Web UI with arguments: --enable-insecure-extension-access --disable-safe-unpickle --share --no-hashing --disable-console-progressbars --lowram --opt-sub-quad-attention --opt-channelslast --no-download-sd-model --gradio-queue --listen --lowram --theme dark --no-half-vae --opt-sdp-attention\n",
            "Total VRAM 15095 MB, total RAM 12976 MB\n",
            "pytorch version: 2.9.0+cu126\n",
            "Set vram state to: NORMAL_VRAM\n",
            "Device: cuda:0 Tesla T4 : native\n",
            "VAE dtype preferences: [torch.float32] -> torch.float32\n",
            "CUDA Using Stream: False\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1767228415.462614   11970 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1767228415.468809   11970 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1767228415.484472   11970 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1767228415.484504   11970 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1767228415.484508   11970 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1767228415.484514   11970 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "Using pytorch cross attention\n",
            "Using pytorch attention for VAE\n",
            "ControlNet preprocessor location: /content/stable-diffusion-webui-forge/models/ControlNetPreprocessor\n",
            "CHv1.8.13: Get Custom Model Folder\n",
            "Tag Autocomplete: Could not locate model-keyword extension, Lora trigger word completion will be limited to those added through the extra networks menu.\n",
            "\u001b[1m[\u001b[0m-\u001b[1m]\u001b[0m ADetailer initialized. version: \u001b[1;36m25.3\u001b[0m.\u001b[1;36m0\u001b[0m, num models: \u001b[1;36m21\u001b[0m\n",
            "\u001b[96mCivitAI Browser+\u001b[0m: Aria2 RPC started\n",
            "*** Error loading script: settings.py\n",
            "    Traceback (most recent call last):\n",
            "      File \"/content/stable-diffusion-webui-forge/modules/scripts.py\", line 525, in load_scripts\n",
            "        script_module = script_loading.load_module(scriptfile.path)\n",
            "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/content/stable-diffusion-webui-forge/modules/script_loading.py\", line 13, in load_module\n",
            "        module_spec.loader.exec_module(module)\n",
            "      File \"<frozen importlib._bootstrap_external>\", line 999, in exec_module\n",
            "      File \"<frozen importlib._bootstrap>\", line 488, in _call_with_frames_removed\n",
            "      File \"/content/stable-diffusion-webui-forge/extensions/sd-webui-civitai-downloader/scripts/settings.py\", line 3, in <module>\n",
            "        from modules.options import OptionDiv\n",
            "    ImportError: cannot import name 'OptionDiv' from 'modules.options' (/content/stable-diffusion-webui-forge/modules/options.py)\n",
            "\n",
            "---\n",
            "*** Error loading script: tab.py\n",
            "    Traceback (most recent call last):\n",
            "      File \"/content/stable-diffusion-webui-forge/modules/scripts.py\", line 525, in load_scripts\n",
            "        script_module = script_loading.load_module(scriptfile.path)\n",
            "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/content/stable-diffusion-webui-forge/modules/script_loading.py\", line 13, in load_module\n",
            "        module_spec.loader.exec_module(module)\n",
            "      File \"<frozen importlib._bootstrap_external>\", line 999, in exec_module\n",
            "      File \"<frozen importlib._bootstrap>\", line 488, in _call_with_frames_removed\n",
            "      File \"/content/stable-diffusion-webui-forge/extensions/sd-webui-civitai-downloader/scripts/tab.py\", line 12, in <module>\n",
            "        from scripts.settings import on_ui_settings\n",
            "      File \"/content/stable-diffusion-webui-forge/extensions/sd-webui-civitai-downloader/scripts/settings.py\", line 3, in <module>\n",
            "        from modules.options import OptionDiv\n",
            "    ImportError: cannot import name 'OptionDiv' from 'modules.options' (/content/stable-diffusion-webui-forge/modules/options.py)\n",
            "\n",
            "---\n",
            "[Vec. CC] Style Sheet Loaded...\n",
            "CHv1.8.13: Set Proxy: \n",
            "[Forge Couple] \u001b[0;32mINFO\u001b[0m - Loaded Adv. Presets...\n",
            "[Forge Couple] \u001b[0;32mINFO\u001b[0m - Loaded Adv. Presets...\n",
            "2026-01-01 00:47:11,359 - ControlNet - \u001b[0;32mINFO\u001b[0m - ControlNet UI callback registered.\n",
            "\u001b[96mCivitAI Browser+\u001b[0m: Basemodel fetch error extracting options: 'issues'\n",
            "[ERROR]: Config states /content/stable-diffusion-webui-forge/config_states/civitai_subfolders.json, \"created_at\" does not exist\n",
            "Model selected: {'checkpoint_info': {'filename': '/content/stable-diffusion-webui-forge/models/Stable-diffusion/redLilyIllu_v10.safetensors', 'hash': '53b2c24d'}, 'additional_modules': [], 'unet_storage_dtype': None}\n",
            "Using online LoRAs in FP16: False\n",
            "Running on local URL:  http://0.0.0.0:7860\n",
            "Running on public URL: https://577e6fd0e48491672d.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n",
            "\u001b[92mIIB Database file has been successfully backed up to the backup folder.\u001b[0m\n",
            "GenParamsGetter detected!\n",
            "GenParamsGetter detected!\n",
            "Startup time: 33.8s (prepare environment: 3.5s, launcher: 0.7s, import torch: 13.3s, other imports: 0.9s, load scripts: 5.3s, create ui: 4.9s, gradio launch: 4.6s, app_started_callback: 0.5s).\n",
            "Environment vars changed: {'stream': False, 'inference_memory': 1024.0, 'pin_shared_memory': False}\n",
            "[GPU Setting] You will use 93.22% GPU memory (14071.00 MB) to load weights, and use 6.78% GPU memory (1024.00 MB) to do matrix computation.\n",
            "INFO:scripts.iib.logger:Version info requested: {'python_version': '3.12.12 (main, Oct 10 2025, 08:52:57) [GCC 11.4.0]', 'platform': 'Linux-6.6.105+-x86_64-with-glibc2.35', 'hash': 'dd5663dd89f08bfea2c87a656459a1c894865d2c', 'tag': 'v1.5.1', 'av': '13.1.0', 'imageio': '2.37.2', 'pillow': '9.5.0', 'imageio_ffmpeg': '0.6.0', 'pillow_avif_plugin': '1.4.3'}\n",
            "Environment vars changed: {'stream': False, 'inference_memory': 1017.0, 'pin_shared_memory': False}\n",
            "[GPU Setting] You will use 93.26% GPU memory (14078.00 MB) to load weights, and use 6.74% GPU memory (1017.00 MB) to do matrix computation.\n",
            "CHv1.8.13: Start scan_model\n",
            "CHv1.8.13: Scanning path: /content/stable-diffusion-webui-forge/embeddings\n",
            "CHv1.8.13: Scanning path: /content/stable-diffusion-webui-forge/models/hypernetworks\n",
            "CHv1.8.13: Scanning path: /content/stable-diffusion-webui-forge/models/Stable-diffusion\n",
            "CHv1.8.13: Scanning path: /content/stable-diffusion-webui-forge/models/Lora\n",
            "CHv1.8.13: Scanning path: /content/stable-diffusion-webui-forge/models/LyCORIS\n",
            "CHv1.8.13: Scanning path: /content/stable-diffusion-webui-forge/models/VAE\n",
            "CHv1.8.13: Creating model info for: redLilyIllu_v10.safetensors\n",
            "CHv1.8.13: SD WebUI Civitai Helper requires hashing functions for this feature.             Please remove the commandline argument `--no-hashing` for this functionality.\n",
            "CHv1.8.13: model action sha256: None\n",
            "CHv1.8.13: failed generating SHA256 for model: redLilyIllu_v10.safetensors\n",
            "CHv1.8.13: Creating model info for: waiIllustriousSDXL_v160.safetensors\n",
            "CHv1.8.13: SD WebUI Civitai Helper requires hashing functions for this feature.             Please remove the commandline argument `--no-hashing` for this functionality.\n",
            "CHv1.8.13: model action sha256: None\n",
            "CHv1.8.13: failed generating SHA256 for model: waiIllustriousSDXL_v160.safetensors\n",
            "CHv1.8.13: Creating model info for: sdxl.vae.safetensors\n",
            "CHv1.8.13: SD WebUI Civitai Helper requires hashing functions for this feature.             Please remove the commandline argument `--no-hashing` for this functionality.\n",
            "CHv1.8.13: model action sha256: None\n",
            "CHv1.8.13: failed generating SHA256 for model: sdxl.vae.safetensors\n",
            "CHv1.8.13: Done. Successfully scanned 0 of 3 models.\n",
            "Interrupted with signal 2 in <frame at 0x78da7dce0400, file '/content/stable-diffusion-webui-forge/modules_forge/main_thread.py', line 43, code loop>\n"
          ]
        }
      ],
      "source": [
        "#@markdown # (3) Start WebUI\n",
        "#@markdown - Be sure to switch the value of \"Diffusion in Low Bits\", from \"Automatic\" to \"float8-e5m2（fp16 LoRA)\" (Only for SDXL not Flux)\n",
        "! {final_args}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Fh8FZx77wqHA"
      },
      "outputs": [],
      "source": [
        "#@markdown # run this to clear gpu vram and ram usage\n",
        "\n",
        "import gc\n",
        "import torch\n",
        "\n",
        "def clear_gpu_memory():\n",
        "  gc.collect()\n",
        "  torch.cuda.empty_cache()\n",
        "\n",
        "clear_gpu_memory()\n",
        "\n",
        "# Optionally, you can also clear RAM usage using the following:\n",
        "# import os\n",
        "# os.system('reset') # This may or may not be effective depending on the environment\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "UyTKsCa1qUL4"
      },
      "outputs": [],
      "source": [
        "# @title ## **Download Generated Images**\n",
        "# @markdown Download file manually from files tab or save to Google Drive\n",
        "import zipfile\n",
        "from pathlib import Path\n",
        "from google.colab import auth\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from oauth2client.client import GoogleCredentials\n",
        "from colablib.colored_print import cprint\n",
        "\n",
        "os.chdir(output_dir)\n",
        "\n",
        "use_drive = False  # @param {type:\"boolean\"}\n",
        "folder_name = \"android-forge-colab\"  # @param {type: \"string\"}\n",
        "filename = \"waifu.zip\"  # @param {type: \"string\"}\n",
        "save_as = filename\n",
        "\n",
        "def get_unique_filename(base_filename):\n",
        "    path = Path(base_filename)\n",
        "    if not path.exists():\n",
        "        return path\n",
        "    i = 1\n",
        "    while True:\n",
        "        new_path = path.with_name(f\"{path.stem}({i}){path.suffix}\")\n",
        "        if not new_path.exists():\n",
        "            return new_path\n",
        "        i += 1\n",
        "\n",
        "filename = get_unique_filename(filename)\n",
        "\n",
        "def zip_directory(directory, zipname):\n",
        "    with zipfile.ZipFile(zipname, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
        "        for file_path in directory.rglob('*'):\n",
        "            if file_path.is_file():\n",
        "                zipf.write(file_path, file_path.relative_to(directory.parent))\n",
        "\n",
        "zip_directory(output_dir, Path('/content/outputs.zip'))\n",
        "\n",
        "if use_drive:\n",
        "    auth.authenticate_user()\n",
        "    gauth = GoogleAuth()\n",
        "    gauth.credentials = GoogleCredentials.get_application_default()\n",
        "    drive_service = GoogleDrive(gauth)\n",
        "\n",
        "    def create_folder(folder_name):\n",
        "        query = f\"title='{folder_name}' and mimeType='application/vnd.google-apps.folder' and trashed=false\"\n",
        "        file_list = drive_service.ListFile({\"q\": query}).GetList()\n",
        "        if file_list:\n",
        "            cprint(\"Debug: Folder exists\", color=\"green\")\n",
        "            return file_list[0][\"id\"]\n",
        "        else:\n",
        "            cprint(\"Debug: Creating folder\", color=\"green\")\n",
        "            folder = drive_service.CreateFile({\n",
        "                \"title\": folder_name,\n",
        "                \"mimeType\": \"application/vnd.google-apps.folder\"\n",
        "            })\n",
        "            folder.Upload()\n",
        "            return folder[\"id\"]\n",
        "\n",
        "    def upload_file(file_path, folder_id, save_as):\n",
        "        save_as = get_unique_filename(save_as)\n",
        "        file = drive_service.CreateFile({\"title\": save_as.name, \"parents\": [{\"id\": folder_id}]})\n",
        "        file.SetContentFile(str(file_path))\n",
        "        file.Upload()\n",
        "        file.InsertPermission({\"type\": \"anyone\", \"value\": \"anyone\", \"role\": \"reader\"})\n",
        "        return file[\"id\"]\n",
        "\n",
        "    folder_id = create_folder(folder_name)\n",
        "    file_id = upload_file(Path('/content/outputs.zip'), folder_id, Path(save_as))\n",
        "    sharing_link = f\"https://drive.google.com/file/d/{file_id}/view?usp=sharing\"\n",
        "    cprint(f\"Your sharing link: {sharing_link}\", color=\"green\")\n",
        "else:\n",
        "    cprint(\"Files zipped locally. Download manually from the files tab.\", color=\"yellow\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}